from flask import Flask, request, jsonify
import onnxruntime as ort
import numpy as np
import cv2
import os
import requests

app = Flask(__name__)

# ===========================
# ğŸ”¹ 1. Táº¢I MODEL Tá»ª HUGGINGFACE
# ===========================
MODEL_URL = "https://huggingface.co/pherodat1104/face_model/resolve/main/face_model.onnx"
MODEL_PATH = "/tmp/models/face_model.onnx"
os.makedirs("/tmp/models", exist_ok=True)

def download_model():
    if os.path.exists(MODEL_PATH):
        print("âœ… Model Ä‘Ã£ cÃ³ sáºµn, bá» qua táº£i láº¡i.")
        return
    print("ğŸ“¥ Äang táº£i model tá»« HuggingFace...")
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(MODEL_URL, headers=headers, stream=True)
    if response.status_code == 200:
        with open(MODEL_PATH, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        print(f"âœ… Model táº£i xong: {MODEL_PATH}")
        print(f"ğŸ“ KÃ­ch thÆ°á»›c: {os.path.getsize(MODEL_PATH)} bytes")
    else:
        print(f"âŒ Lá»—i táº£i model: {response.status_code}")
        raise Exception(f"Lá»—i táº£i model tá»« HuggingFace ({response.status_code})")

# Táº£i model khi khá»Ÿi Ä‘á»™ng
download_model()

# ===========================
# ğŸ”¹ 2. LOAD MODEL
# ===========================
print("ğŸ”„ Äang load model ONNX...")
ort_session = ort.InferenceSession(MODEL_PATH)
print("âœ… Model ONNX Ä‘Ã£ load thÃ nh cÃ´ng!")

# ===========================
# ğŸ”¹ 3. ROUTE Gá»C â€” KIá»‚M TRA SERVER
# ===========================
@app.route("/", methods=["GET"])
def home():
    return jsonify({
        "message": "âœ… SmartClock Server Ä‘ang hoáº¡t Ä‘á»™ng!",
        "status": "online",
        "model_loaded": os.path.exists(MODEL_PATH)
    })

# ===========================
# ğŸ”¹ 4. ROUTE UPLOAD áº¢NH
# ===========================
@app.route("/upload", methods=["POST"])
def upload_image():
    try:
        if "image" not in request.files:
            return jsonify({"error": "KhÃ´ng cÃ³ file 'image' trong request!"}), 400

        file = request.files["image"]
        image_bytes = np.frombuffer(file.read(), np.uint8)
        img = cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)

        if img is None:
            return jsonify({"error": "KhÃ´ng Ä‘á»c Ä‘Æ°á»£c áº£nh!"}), 400

        # Resize áº£nh cho khá»›p model (vÃ­ dá»¥: 112x112)
        img_resized = cv2.resize(img, (112, 112))
        img_resized = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
        img_tensor = img_resized.astype(np.float32) / 255.0
        img_tensor = np.transpose(img_tensor, (2, 0, 1))  # CHW
        img_tensor = np.expand_dims(img_tensor, axis=0)  # NCHW

        # Dá»± Ä‘oÃ¡n
        ort_inputs = {ort_session.get_inputs()[0].name: img_tensor}
        emb = ort_session.run(None, ort_inputs)[0]

        emb_mean = np.mean(emb)
        print(f"âœ… Nháº­n áº£nh OK - mean embedding: {emb_mean:.6f}")

        return jsonify({
            "status": "success",
            "embedding_mean": float(emb_mean)
        })

    except Exception as e:
        print(f"âŒ Lá»—i xá»­ lÃ½ upload: {e}")
        return jsonify({"error": str(e)}), 500

# ===========================
# ğŸ”¹ 5. KHá»I CHáº Y
# ===========================
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    print(f"ğŸš€ Server Ä‘ang cháº¡y táº¡i cá»•ng {port}")
    app.run(host="0.0.0.0", port=port)
